{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulate the Pheno-type data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Choose $n = 20$ genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\OneDrive\\Programming\\Python\\bio_informatics\n",
      "['a.txt', 'Chr1First2000 - 副本.vcf', 'Chr1First2000.vcf', 'eg.vcf', 'filtered_test.vcf', 'selected_genes.csv', 'SNP_in_200GENE_chr1.csv', 'SNP_in_20GENE_chr1.csv', 'test.csv']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archibald\\AppData\\Local\\Temp\\ipykernel_29016\\2278546344.py:4: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file, error_bad_lines=False)\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "print(os.listdir('./data'))\n",
    "file = 'data/SNP_in_200GENE_chr1.csv'\n",
    "data = pd.read_csv(file, error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10297\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENE</th>\n",
       "      <th>POS</th>\n",
       "      <th>HG00096</th>\n",
       "      <th>HG00097</th>\n",
       "      <th>HG00099</th>\n",
       "      <th>HG00100</th>\n",
       "      <th>HG00101</th>\n",
       "      <th>HG00102</th>\n",
       "      <th>HG00103</th>\n",
       "      <th>HG00104</th>\n",
       "      <th>...</th>\n",
       "      <th>NA21128</th>\n",
       "      <th>NA21129</th>\n",
       "      <th>NA21130</th>\n",
       "      <th>NA21133</th>\n",
       "      <th>NA21135</th>\n",
       "      <th>NA21137</th>\n",
       "      <th>NA21141</th>\n",
       "      <th>NA21142</th>\n",
       "      <th>NA21143</th>\n",
       "      <th>NA21144</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269039</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269650</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2550 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              GENE      POS  HG00096  HG00097  HG00099  HG00100  HG00101  \\\n",
       "0  ENSG00000227634  8269039        2        2        1        2        2   \n",
       "1  ENSG00000227634  8269341        0        0        0        0        0   \n",
       "2  ENSG00000227634  8269373        2        2        1        2        2   \n",
       "3  ENSG00000227634  8269650        2        2        1        2        2   \n",
       "4  ENSG00000227634  8269712        0        0        0        0        0   \n",
       "\n",
       "   HG00102  HG00103  HG00104  ...  NA21128  NA21129  NA21130  NA21133  \\\n",
       "0        1        1        2  ...        1        2        1        2   \n",
       "1        0        0        0  ...        0        0        0        0   \n",
       "2        1        1        2  ...        1        2        1        2   \n",
       "3        1        1        2  ...        1        2        1        1   \n",
       "4        0        0        0  ...        0        0        0        0   \n",
       "\n",
       "   NA21135  NA21137  NA21141  NA21142  NA21143  NA21144  \n",
       "0        1        2        2        1        2        1  \n",
       "1        0        0        0        0        0        0  \n",
       "2        1        2        2        1        2        1  \n",
       "3        1        2        2        1        2        1  \n",
       "4        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 2550 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENE</th>\n",
       "      <th>POS</th>\n",
       "      <th>HG00096</th>\n",
       "      <th>HG00097</th>\n",
       "      <th>HG00099</th>\n",
       "      <th>HG00100</th>\n",
       "      <th>HG00101</th>\n",
       "      <th>HG00102</th>\n",
       "      <th>HG00103</th>\n",
       "      <th>HG00104</th>\n",
       "      <th>...</th>\n",
       "      <th>NA21129</th>\n",
       "      <th>NA21130</th>\n",
       "      <th>NA21133</th>\n",
       "      <th>NA21135</th>\n",
       "      <th>NA21137</th>\n",
       "      <th>NA21141</th>\n",
       "      <th>NA21142</th>\n",
       "      <th>NA21143</th>\n",
       "      <th>NA21144</th>\n",
       "      <th>gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269039</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269341</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269650</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000227634</td>\n",
       "      <td>8269712</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000227634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              GENE      POS  HG00096  HG00097  HG00099  HG00100  HG00101  \\\n",
       "0  ENSG00000227634  8269039        2        2        1        2        2   \n",
       "1  ENSG00000227634  8269341        0        0        0        0        0   \n",
       "2  ENSG00000227634  8269373        2        2        1        2        2   \n",
       "3  ENSG00000227634  8269650        2        2        1        2        2   \n",
       "4  ENSG00000227634  8269712        0        0        0        0        0   \n",
       "\n",
       "   HG00102  HG00103  HG00104  ...  NA21129  NA21130  NA21133  NA21135  \\\n",
       "0        1        1        2  ...        2        1        2        1   \n",
       "1        0        0        0  ...        0        0        0        0   \n",
       "2        1        1        2  ...        2        1        2        1   \n",
       "3        1        1        2  ...        2        1        1        1   \n",
       "4        0        0        0  ...        0        0        0        0   \n",
       "\n",
       "   NA21137  NA21141  NA21142  NA21143  NA21144             gene  \n",
       "0        2        2        1        2        1  ENSG00000227634  \n",
       "1        0        0        0        0        0  ENSG00000227634  \n",
       "2        2        2        1        2        1  ENSG00000227634  \n",
       "3        2        2        1        2        1  ENSG00000227634  \n",
       "4        0        0        0        0        0  ENSG00000227634  \n",
       "\n",
       "[5 rows x 2551 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gene'] = data.GENE.astype('category')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gene\n",
       "ENSG00000001461    [ENSG00000001461]\n",
       "ENSG00000018625    [ENSG00000018625]\n",
       "ENSG00000084070    [ENSG00000084070]\n",
       "ENSG00000084072    [ENSG00000084072]\n",
       "ENSG00000116147    [ENSG00000116147]\n",
       "                         ...        \n",
       "ENSG00000268172    [ENSG00000268172]\n",
       "ENSG00000271647    [ENSG00000271647]\n",
       "ENSG00000271810    [ENSG00000271810]\n",
       "ENSG00000272084    [ENSG00000272084]\n",
       "ENSG00000273002    [ENSG00000273002]\n",
       "Name: GENE, Length: 136, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('gene').GENE.unique().sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoricalIndex(['ENSG00000116704', 'ENSG00000162378', 'ENSG00000162374',\n",
      "                  'ENSG00000168710', 'ENSG00000121644', 'ENSG00000116353',\n",
      "                  'ENSG00000237413', 'ENSG00000143190', 'ENSG00000203739',\n",
      "                  'ENSG00000134198', 'ENSG00000153207', 'ENSG00000229956',\n",
      "                  'ENSG00000198198', 'ENSG00000172380', 'ENSG00000143702',\n",
      "                  'ENSG00000225006', 'ENSG00000117461', 'ENSG00000117602',\n",
      "                  'ENSG00000143344', 'ENSG00000162688'],\n",
      "                 categories=['ENSG00000001461', 'ENSG00000018625', 'ENSG00000084070', 'ENSG00000084072', 'ENSG00000116147', 'ENSG00000116353', 'ENSG00000116497', 'ENSG00000116704', ...], ordered=False, dtype='category', name='gene')\n"
     ]
    }
   ],
   "source": [
    "# Selecting 20 Genes that have more than 100 SNPs\n",
    "n = 20\n",
    "counts = data.groupby('gene').size().sort_values(ascending=False) \n",
    "groups = counts[counts > 100].sample(n, replace = False, random_state = 1 ).index\n",
    "\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5443\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GENE</th>\n",
       "      <th>POS</th>\n",
       "      <th>HG00096</th>\n",
       "      <th>HG00097</th>\n",
       "      <th>HG00099</th>\n",
       "      <th>HG00100</th>\n",
       "      <th>HG00101</th>\n",
       "      <th>HG00102</th>\n",
       "      <th>HG00103</th>\n",
       "      <th>HG00104</th>\n",
       "      <th>...</th>\n",
       "      <th>NA21129</th>\n",
       "      <th>NA21130</th>\n",
       "      <th>NA21133</th>\n",
       "      <th>NA21135</th>\n",
       "      <th>NA21137</th>\n",
       "      <th>NA21141</th>\n",
       "      <th>NA21142</th>\n",
       "      <th>NA21143</th>\n",
       "      <th>NA21144</th>\n",
       "      <th>gene</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24830297</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24831517</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24832009</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24835018</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>ENSG00000117602</td>\n",
       "      <td>24835171</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ENSG00000117602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2551 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                GENE       POS  HG00096  HG00097  HG00099  HG00100  HG00101  \\\n",
       "331  ENSG00000117602  24830297        2        2        2        2        2   \n",
       "332  ENSG00000117602  24831517        2        2        2        2        2   \n",
       "333  ENSG00000117602  24832009        2        2        1        0        1   \n",
       "334  ENSG00000117602  24835018        2        2        1        2        2   \n",
       "335  ENSG00000117602  24835171        0        0        1        2        1   \n",
       "\n",
       "     HG00102  HG00103  HG00104  ...  NA21129  NA21130  NA21133  NA21135  \\\n",
       "331        2        2        2  ...        2        2        2        2   \n",
       "332        2        2        2  ...        2        2        2        2   \n",
       "333        2        2        1  ...        1        2        2        0   \n",
       "334        1        1        1  ...        2        1        2        2   \n",
       "335        0        0        1  ...        1        0        0        2   \n",
       "\n",
       "     NA21137  NA21141  NA21142  NA21143  NA21144             gene  \n",
       "331        2        2        2        2        2  ENSG00000117602  \n",
       "332        2        2        2        2        2  ENSG00000117602  \n",
       "333        2        2        1        0        0  ENSG00000117602  \n",
       "334        2        2        2        2        2  ENSG00000117602  \n",
       "335        0        0        1        2        2  ENSG00000117602  \n",
       "\n",
       "[5 rows x 2551 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = [i for i,x in enumerate(data['gene']) if x in groups]\n",
    "data_selected = data.iloc[index, :]\n",
    "print(len(data_selected))\n",
    "data_selected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5443, 2551)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archibald\\AppData\\Local\\Temp\\ipykernel_29016\\486112115.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected['sign'] = 0\n"
     ]
    }
   ],
   "source": [
    "# get the group names\n",
    "gene_names = list(data_selected.gene.unique())\n",
    "\n",
    "data_selected['sign'] = 0\n",
    "\n",
    "# Choose five SNPs as significant SNPs and 95 as small sigficance others are non-significant\n",
    "for gene in gene_names:\n",
    "    n = len(data_selected.loc[data_selected['gene'] == gene ,:])\n",
    "    sign =  [1] * 100  + [0] * (n - 100)\n",
    "    \n",
    "    data_selected.loc[data_selected['gene'] == gene ,'sign'] = sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Archibald\\AppData\\Local\\Temp\\ipykernel_29016\\1514404415.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_selected['sign'][:d] = 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000, 2552)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 5\n",
    "data_selected = data_selected.loc[data_selected['sign'] != 0,:]\n",
    "data_selected['sign'][:d] = 2\n",
    "data_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "331    2\n",
       "332    2\n",
       "333    2\n",
       "334    2\n",
       "335    2\n",
       "Name: sign, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_selected['sign'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1995\n",
      "331    24.947468\n",
      "332     5.659078\n",
      "333    13.841445\n",
      "334    31.691016\n",
      "335    26.411258\n",
      "336    -1.692695\n",
      "337     1.645601\n",
      "338    -0.262158\n",
      "339    -0.178780\n",
      "340     0.711177\n",
      "Name: beta, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Beta\n",
    "np.random.seed(0)\n",
    "data_selected['beta'] = 0\n",
    "n = len(data_selected.loc[data_selected['sign'] == 2,'beta'])\n",
    "print(n)\n",
    "large_effect = 200\n",
    "data_selected.loc[data_selected['sign'] == 2,'beta'] = np.random.normal(0, np.sqrt(large_effect), n)\n",
    "\n",
    "n = len(data_selected.loc[data_selected['sign'] == 1,'beta'])\n",
    "print(n)\n",
    "small_effect = 3\n",
    "data_selected.loc[data_selected['sign'] == 1,'beta'] = np.random.normal(0, np.sqrt(small_effect), n)\n",
    "\n",
    "beta = data_selected.beta\n",
    "print(beta[:10])\n",
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>340</th>\n",
       "      <th>...</th>\n",
       "      <th>9963</th>\n",
       "      <th>9964</th>\n",
       "      <th>9965</th>\n",
       "      <th>9966</th>\n",
       "      <th>9967</th>\n",
       "      <th>9968</th>\n",
       "      <th>9969</th>\n",
       "      <th>9970</th>\n",
       "      <th>9971</th>\n",
       "      <th>9972</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         331   332   333   334   335   336   337   338   339   340   ...  \\\n",
       "HG00096     2     2     2     2     0     0     2     0     2     0  ...   \n",
       "HG00097     2     2     2     2     0     0     2     0     2     0  ...   \n",
       "HG00099     2     2     1     1     1     0     1     1     1     1  ...   \n",
       "HG00100     2     2     0     2     2     0     0     2     0     2  ...   \n",
       "HG00101     2     2     1     2     1     0     1     1     1     1  ...   \n",
       "\n",
       "         9963  9964  9965  9966  9967  9968  9969  9970  9971  9972  \n",
       "HG00096     1     1     1     0     1     0     1     0     0     0  \n",
       "HG00097     1     1     1     0     1     0     1     0     0     0  \n",
       "HG00099     0     0     1     0     0     0     0     0     0     0  \n",
       "HG00100     1     1     1     0     1     0     1     0     0     0  \n",
       "HG00101     1     1     1     0     1     0     1     0     0     0  \n",
       "\n",
       "[5 rows x 2000 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.preprocessing import StandardScaler \n",
    "SNP = data_selected.drop(['GENE', 'POS', 'gene', 'beta'], axis=1).T\n",
    "# ss = StandardScaler()\n",
    "# SNP.loc[:,:] = ss.fit_teansform(X = SNP.loc[:,:])\n",
    "\n",
    "SNP.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP1 = SNP.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2549,)\n",
      "The sigma_g^2 is 2609.2, and sigma_e^2 is 2609.2\n"
     ]
    }
   ],
   "source": [
    "temp = SNP1.values @ beta\n",
    "print(temp.shape)\n",
    "sigma_g2 = np.var(temp, ddof = 1) # get the overall variance\n",
    "h2 = 0.5 # heritability\n",
    "sigma_e2 = sigma_g2 * (1 - h2)/ h2\n",
    "print(\"The sigma_g^2 is {:.5}, and sigma_e^2 is {:.5}\".format(sigma_g2, sigma_e2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add bias term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'large_effect' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\OneDrive\\Programming\\Python\\bio_informatics\\simulation.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/bio_informatics/simulation.ipynb#ch0000019?line=0'>1</a>\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m1\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/bio_informatics/simulation.ipynb#ch0000019?line=1'>2</a>\u001b[0m beta0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\u001b[39m0\u001b[39m, np\u001b[39m.\u001b[39msqrt(large_effect))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/bio_informatics/simulation.ipynb#ch0000019?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(beta0)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/OneDrive/Programming/Python/bio_informatics/simulation.ipynb#ch0000019?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(beta\u001b[39m.\u001b[39mshape)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'large_effect' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "beta0 = np.random.normal(0, np.sqrt(large_effect))\n",
    "print(beta0)\n",
    "print(beta.shape)\n",
    "# beta_ = np.append(beta, beta0)\n",
    "beta_ = np.insert(beta, 0, beta0)\n",
    "print(beta_[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNP.insert(loc=0, column='bias', value=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2549, 2001)\n",
      "(2001,)\n"
     ]
    }
   ],
   "source": [
    "residual = np.random.normal(0, np.sqrt(sigma_e2), len(SNP))\n",
    "print(SNP.values.shape)\n",
    "print(beta_.shape)\n",
    "SNP['Y'] = SNP1.values @ beta + residual + beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>...</th>\n",
       "      <th>9964</th>\n",
       "      <th>9965</th>\n",
       "      <th>9966</th>\n",
       "      <th>9967</th>\n",
       "      <th>9968</th>\n",
       "      <th>9969</th>\n",
       "      <th>9970</th>\n",
       "      <th>9971</th>\n",
       "      <th>9972</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.792189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.151941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.198573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bias  331  332  333  334  335  336  337  338  339  ...  9964  9965  \\\n",
       "HG00096     1    2    2    2    2    0    0    2    0    2  ...     1     1   \n",
       "HG00097     1    2    2    2    2    0    0    2    0    2  ...     1     1   \n",
       "HG00099     1    2    2    1    1    1    0    1    1    1  ...     0     1   \n",
       "HG00100     1    2    2    0    2    2    0    0    2    0  ...     1     1   \n",
       "HG00101     1    2    2    1    2    1    0    1    1    1  ...     1     1   \n",
       "\n",
       "         9966  9967  9968  9969  9970  9971  9972           Y  \n",
       "HG00096     0     1     0     1     0     0     0   89.377100  \n",
       "HG00097     0     1     0     1     0     0     0   97.792189  \n",
       "HG00099     0     0     0     0     0     0     0    7.652598  \n",
       "HG00100     0     1     0     1     0     0     0  121.151941  \n",
       "HG00101     0     1     0     1     0     0     0  -18.198573  \n",
       "\n",
       "[5 rows x 2002 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SNP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Simulated Parameters and data\n",
    "SNP.to_csv('data/Simulated_SNPs.csv')\n",
    "np.savez('Parameters/simulated_parameters.npz', sigma_e2 =sigma_e2,sigma_g2 =sigma_g2, h2 = h2, beta = beta_, large_effect_terms = d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with K-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds_indices(nfolds, n_tr):\n",
    "    if nfolds <= n_tr:\n",
    "        fold_size = int(np.floor(n_tr/nfolds))\n",
    "        resi = n_tr % nfolds\n",
    "        fold_sizes = [0] + resi * [fold_size +1] + (nfolds - resi) * [fold_size]\n",
    "        indices = np.cumsum(fold_sizes)\n",
    "        folds_indices = [(indices[i], indices[i + 1])  for i in range(nfolds)]\n",
    "\n",
    "    else:\n",
    "        raise Exception(\"Number of folds is larger than numer of samples\")\n",
    "    print('First 5 fold indices : {}'.format(folds_indices[:5]))\n",
    "    return folds_indices\n",
    "    \n",
    "def getHcv_for_Kfolds(X_tr, y_tr,  H_function, V = None, nfolds = 10):\n",
    "    n_tr,p = X_tr.shape\n",
    "    Hcv_k = np.zeros([n_tr,n_tr])\n",
    "    \n",
    "    folds_indices = get_folds_indices(nfolds = nfolds, n_tr = n_tr)\n",
    "    for Kindices in folds_indices:\n",
    "        ia,ib = Kindices\n",
    "        indices_minus_K = list(range(0, ia)) + list(range(ib, n_tr))\n",
    "\n",
    "        X_minus_K = X_tr[indices_minus_K,:]\n",
    "        y_minus_K = y_tr[indices_minus_K]\n",
    "        X_k = X_tr[ia:ib,:]\n",
    "        y_K = y_tr[ia:ib]\n",
    "\n",
    "        if V is not None:\n",
    "            V_minus_k = V[indices_minus_K,:][:, indices_minus_K]\n",
    "            temp = H_function(X_minus_K, X_k , y_minus_K, y_K, V_minus_k)\n",
    "        else:\n",
    "            temp = H_function(X_minus_K, X_k , y_minus_K, y_K)\n",
    "\n",
    "        Hcv_k[ia:ib, indices_minus_K] = temp\n",
    "\n",
    "    return Hcv_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. LMM (linear mixed model)\n",
    "Let the model be\n",
    "$$\n",
    "Y_i = \\sum_{j = 1}^{p} \\beta_j X_{i,j} + u_i +\\epsilon_i \\ \\text{where } i = 1, 2,3,\\dots,n\n",
    "$$\n",
    "where $(u_1, u_2, \\dots, u_n)^\\top \\sim MVN(0, \\sigma_g^2 K ) $ and $\\epsilon_i \\sim ^{i.i.d} N(0, \\sigma_e^2)$, and  $K = 1/p X X^\\top$, $\\sigma_e^2 = \\frac{1 - h^2}{h^2} \\sigma_g^2$ . \n",
    "\n",
    "> ? how to estimate $\\sigma_e \\text{ and } \\sigma_g$?  Maybe using REML? But it requires the indication of the clusters.\n",
    "\n",
    "We can write the model as \n",
    "$$\n",
    "Y_i = \\sum_{j = 1}^{p} \\beta_j X_{i,j} + \\epsilon_i^* \\ \\text{where } i = 1, 2,3,\\dots,n \\text{ and } \\boldsymbol{\\epsilon}^{*} = \\boldsymbol u + \\boldsymbol \\epsilon \\sim N_{n}(\\mathbf{0}, V)\n",
    "$$\n",
    "where $V = Var(Y|X\\beta) = \\sigma^2_g K + \\sigma^2_e I$\n",
    "\n",
    "So we need to estimate two of  $\\sigma_g, \\sigma_e \\text{or } h$\n",
    "\n",
    "so we can get estimate for $\\tilde{\\boldsymbol{\\beta}}:=\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1} \\boldsymbol{Y}$\n",
    "\n",
    "BLUP for $\\tilde u = E(u|Y) = \\sigma^2_g K V^{-1}(Y - X\\tilde \\beta)$\n",
    "\n",
    " And $\\hat Y = X \\tilde \\beta + \\tilde u$\n",
    "\n",
    "Now we can define $H$ by\n",
    "\n",
    "$H = X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1} + \\sigma^2_g K V^{-1}(I - X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1})$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\widehat{C V}_{c}=\\frac{1}{n}\\left(\\boldsymbol{y}-H_{c v} \\boldsymbol{y}\\right)^{t}\\left(\\boldsymbol{y}-H_{c v} \\boldsymbol{y}\\right)+\\frac{2}{n}\\left[\\operatorname{tr}\\left(H_{c v} \\operatorname{Cov}(\\boldsymbol{y}, \\boldsymbol{y})\\right)-n \\boldsymbol{h}_{t e} \\operatorname{Cov}\\left(\\boldsymbol{y}_{t r}, y_{t e}\\right)\\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>331</th>\n",
       "      <th>332</th>\n",
       "      <th>333</th>\n",
       "      <th>334</th>\n",
       "      <th>335</th>\n",
       "      <th>336</th>\n",
       "      <th>337</th>\n",
       "      <th>338</th>\n",
       "      <th>339</th>\n",
       "      <th>...</th>\n",
       "      <th>9964</th>\n",
       "      <th>9965</th>\n",
       "      <th>9966</th>\n",
       "      <th>9967</th>\n",
       "      <th>9968</th>\n",
       "      <th>9969</th>\n",
       "      <th>9970</th>\n",
       "      <th>9971</th>\n",
       "      <th>9972</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89.377100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97.792189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.652598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121.151941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.198573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2002 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bias  331  332  333  334  335  336  337  338  339  ...  9964  9965  \\\n",
       "HG00096     1    2    2    2    2    0    0    2    0    2  ...     1     1   \n",
       "HG00097     1    2    2    2    2    0    0    2    0    2  ...     1     1   \n",
       "HG00099     1    2    2    1    1    1    0    1    1    1  ...     0     1   \n",
       "HG00100     1    2    2    0    2    2    0    0    2    0  ...     1     1   \n",
       "HG00101     1    2    2    1    2    1    0    1    1    1  ...     1     1   \n",
       "\n",
       "         9966  9967  9968  9969  9970  9971  9972           Y  \n",
       "HG00096     0     1     0     1     0     0     0   89.377100  \n",
       "HG00097     0     1     0     1     0     0     0   97.792189  \n",
       "HG00099     0     0     0     0     0     0     0    7.652598  \n",
       "HG00100     0     1     0     1     0     0     0  121.151941  \n",
       "HG00101     0     1     0     1     0     0     0  -18.198573  \n",
       "\n",
       "[5 rows x 2002 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "if not 'SNP' in locals():\n",
    "    SNP = pd.read_csv('data/Simulated_SNPs.csv', index_col=0)\n",
    "par = np.load('Parameters/simulated_parameters.npz')\n",
    "sigma_e2, sigma_g2, h2, beta, num_large_effet_terms = [par[params] for params in par.files]\n",
    "sigma_g2 = float(sigma_g2)\n",
    "sigma_e2 = float(sigma_e2)\n",
    "h2 = float(h2)\n",
    "SNP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.97171243, 24.94746752,  5.65907751, 13.84144531, 31.69101554,\n",
       "       26.41125838])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta[:num_large_effet_terms+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get $V = Var(Y|X\\beta) = \\sigma^2_g K + \\sigma^2_e I$ where $K = 1/p X X^\\top$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "SNP_ = SNP.copy()\n",
    "SNP_.drop('Y', inplace= True, axis = 1)\n",
    "data = SNP_.values\n",
    "G_tr, G_te, y_tr, y_te = train_test_split(data, SNP['Y'].to_numpy().reshape([-1,1]), test_size = 0.2, random_state = 123)\n",
    "X_tr, X_te = G_tr[:, :num_large_effet_terms+1], G_te[:, :num_large_effet_terms+1]\n",
    "W_tr, W_te = G_tr[:, 1:], G_te[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2039, 1) (2039, 6) (2039, 2000) (510, 1) (510, 6) (510, 2000)\n"
     ]
    }
   ],
   "source": [
    "print(y_tr.shape, X_tr.shape, W_tr.shape, y_te.shape, X_te.shape, W_te.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using FAST_LMM to estimate sigma_g2 and sigma_e2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import uitls from the calling time\n",
      "------------- FAST-LMM------------------\n",
      "LowRank is set as True, using REML\n",
      "Rank of W is 1673, shape of W is (2039, 2000).\n",
      "Optimization Results:\n",
      "Delta is calculated as:  0.5955727153476151\n",
      "Maximum REML is calculated as:  -11030.798258070256\n",
      "---------------Summary------------------\n",
      "LowRank is set as True, using REML\n",
      "Heritability h2: 0.6267342067090548\n",
      "Sigma_g2: 4407.204534663662\n",
      "Sigma_e2: 2624.81077180196\n",
      "------ 5.080962181091309 seconds ------\n"
     ]
    }
   ],
   "source": [
    "# from FAST_LMM import utils as u\n",
    "sc = W_tr.shape[1]\n",
    "from FAST_LMM import FASTLMM\n",
    "fast = FASTLMM(lowRank=True, REML = True)\n",
    "fast.fit(X_tr, y_tr, 1/np.sqrt(sc) * W_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fast.plot_likelihood()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h2 =  0.6267342067090548\n",
      "5437.275694279155 7401.588262106941 5851.42411622923\n"
     ]
    }
   ],
   "source": [
    "#using theoreatical sigma\n",
    "# fast.sigma_e2 = sigma_e2\n",
    "# fast.sigma_g2 = sigma_g2\n",
    "\n",
    "print('h2 = ', 1/(1+fast.delta) )\n",
    "n, sc = W_tr.shape\n",
    "varYhat = np.mean(np.diag(1/ sc * sigma_g2* W_tr @ W_tr.T + sigma_e2 * np.identity(n)))\n",
    "varYhat2 = np.mean(np.diag(1/ sc * fast.sigma_g2* W_tr @ W_tr.T + fast.sigma_e2 * np.identity(n)))\n",
    "varY = np.var(y_tr - X_tr @ beta[ :num_large_effet_terms+1], ddof = 0)\n",
    "print(varYhat, varYhat2, varY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_te, sc_te = W_te.shape\n",
    "y_te_hat = fast.predict(X_te,  1/np.sqrt(sc_te)* W_te)\n",
    "y_tr_hat = fast.predict(X_tr, 1/np.sqrt(sc)* W_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr_hat_wls = X_tr @ fast.beta\n",
    "y_te_hat_wls = X_te @ fast.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMM: training error is: 2406.141720451171  test error is: 3124.1619371842025\n",
      "WLS: training error is: 4070.0083771106006  test error is: 4487.270237840345\n"
     ]
    }
   ],
   "source": [
    "tr_error = 1/n * (np.sum(np.square(y_tr_hat - y_tr)))\n",
    "te_error = 1/n_te * (np.sum(np.square(y_te_hat - y_te)))\n",
    "tr_error_wls = 1/n * (np.sum(np.square(y_tr_hat_wls - y_tr)))\n",
    "te_error_wls = 1/n_te * (np.sum(np.square(y_te_hat_wls - y_te)))\n",
    "print('LMM: training error is:', tr_error, ' test error is:', te_error)\n",
    "print('WLS: training error is:', tr_error_wls, ' test error is:', te_error_wls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of training and test error of using LMM, OLS, WLS\n",
    "First we calculate $H_{tr, LMM}$, which is $H = X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1} + \\sigma^2_g K V^{-1}(I - X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1})$\n",
    "\n",
    "Then we calculate $H_{tr, WLS}$, which is $H = X\\left(X^{t} V^{-1} X\\right)^{-1} X^{t} V^{-1}$.\n",
    "\n",
    "Finally we calculate $H_{tr, WLS}$, which is $H = X\\left(X^{t} X\\right)^{-1} X^{t}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FAST_LMM.FAST_LMM import utils as u\n",
    "n_tr,sc = W_tr.shape\n",
    "V_inv = fast.sigma_g2 / sc * W_tr @ W_tr.T + fast.sigma_e2 * np.identity(X_tr.shape[0])\n",
    "inverse_part = u.inv(X_tr.T @ fast.V_inv() @ X_tr)\n",
    "\n",
    "K = W_tr @ W_tr.T /sc\n",
    "H_wls = X_tr @ inverse_part @ X_tr.T @ fast.V_inv()\n",
    "add2 = sigma_g2 * K @ fast.V_inv() @ (np.identity(n_tr) - H_wls)\n",
    "H_lmm = H_wls + add2\n",
    "H_ols = X_tr @ u.inv(X_tr.T @ X_tr)@ X_tr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training error of lmm is 2412.40, wls error is 4065.82, ols error is 3935.42, sigma_e2 is 2609.24\n",
      "The ratio is 1.00 : 1.86 : 1.63\n"
     ]
    }
   ],
   "source": [
    "y_tr_hat_lmm = H_lmm @ y_tr\n",
    "y_tr_hat_wls = H_wls @ y_tr\n",
    "y_tr_hat_ols = H_ols @ y_tr \n",
    "\n",
    "\n",
    "tr_error_lmm = 1/n_tr * (np.sum((y_tr - y_tr_hat)**2))\n",
    "tr_error_ols = 1/n_tr * (np.sum((y_tr - y_tr_hat_ols)**2))\n",
    "tr_error_wls = 1/n_tr * (np.sum((y_tr - y_tr_hat_wls)**2))\n",
    "\n",
    "print('Training error of lmm is {:.2f}, wls error is {:.2f}, ols error is {:.2f}, sigma_e2 is {:.2f}'.format(\n",
    "    tr_error_lmm, tr_error_wls, tr_error_ols, fast.sigma_e2))\n",
    "print('The ratio is {:.2f} : {:.2f} : {:.2f}'.format(1, te_error_wls/tr_error_lmm, tr_error_ols/tr_error_lmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr,sc = W_tr.shape\n",
    "# V = fast.sigma_g2 / sc * W_tr @ W_tr.T + fast.sigma_e2 * np.identity(X_tr.shape[0])\n",
    "inverse_part = u.inv(X_tr.T @ fast.V_inv() @ X_tr)\n",
    "\n",
    "H_wls_te = X_te @ inverse_part @ X_tr.T @ fast.V_inv()\n",
    "K_te_tr = W_te @ W_tr.T /sc\n",
    "add2 = sigma_g2 * K_te_tr @ fast.V_inv() @ (np.identity(n_tr) - H_wls)\n",
    "H_lmm_te = H_wls_te + add2\n",
    "H_ols_te = X_te @ u.inv(X_tr.T @ X_tr)@ X_tr.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test error of lmm is 3125.19, wls error is 4482.01, ols error is 4301.22, sigma_e2 is 2609.24\n",
      "The ratio is 1.00 : 1.43 : 1.38\n"
     ]
    }
   ],
   "source": [
    "y_te_hat_lmm = H_lmm_te @ y_tr\n",
    "y_te_hat_wls = H_wls_te @ y_tr\n",
    "y_te_hat_ols = H_ols_te @ y_tr\n",
    "\n",
    "te_error_lmm = 1/n_te * (np.sum((y_te - y_te_hat_lmm)**2))\n",
    "te_error_ols = 1/n_te * (np.sum((y_te - y_te_hat_ols)**2))\n",
    "te_error_wls = 1/n_te * (np.sum((y_te - y_te_hat_wls)**2))\n",
    "\n",
    "print('test error of lmm is {:.2f}, wls error is {:.2f}, ols error is {:.2f}, sigma_e2 is {:.2f}'.format(\n",
    "    te_error_lmm, te_error_wls, te_error_ols, fast.sigma_e2))\n",
    "print('The ratio is {:.2f} : {:.2f} : {:.2f}'.format(1, te_error_wls/te_error_lmm, te_error_ols/te_error_lmm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training error of     lmm is 2406.141720451171, wls is 4070.0083771106233, and ols is 3935.421037480194\n",
      "The corrected tr error of lmm is 2923.152277367677, wls is 4087.9984811646773, and ols is 3981.954523067176\n",
      "The test error of         lmm is 3124.1619371842066, wls is 4487.270237840382, and ols is 4301.224827649088\n"
     ]
    }
   ],
   "source": [
    "V_tr_te = 1/sc * W_tr @ W_te.T * sigma_g2\n",
    "w_lmm = 2 *( 1/n_tr * np.trace(H_lmm @ fast.V()) - 1/ n_te * np.trace(H_lmm_te @ V_tr_te))\n",
    "w_wls = 2 *( 1/n_tr * np.trace(H_wls @ fast.V()) - 1/ n_te * np.trace(H_wls_te @ V_tr_te))\n",
    "w_ols = 2 *( 1/n_tr * np.trace(H_ols @ fast.V()) - 1/ n_te * np.trace(H_ols_te @ V_tr_te))\n",
    "\n",
    "\n",
    "tr_error_lmm_c = tr_error_lmm + w_lmm\n",
    "tr_error_wls_c = tr_error_wls + w_wls\n",
    "tr_error_ols_c = tr_error_ols + w_ols\n",
    "\n",
    "print('The training error of     lmm is {}, wls is {}, and ols is {}'.format(tr_error_lmm, tr_error_wls, tr_error_ols))\n",
    "print('The corrected tr error of lmm is {}, wls is {}, and ols is {}'.format(tr_error_lmm_c, tr_error_wls_c, tr_error_ols_c))\n",
    "print('The test error of         lmm is {}, wls is {}, and ols is {}'.format(te_error_lmm, te_error_wls, te_error_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leave One out Cross-validation error of LMM WLS and OLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using theoretical sigma values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma_e2:  2609.2370423738284  sigma_g2:  2609.2370423738284\n"
     ]
    }
   ],
   "source": [
    "print('sigma_e2: ', sigma_e2, ' sigma_g2: ', sigma_g2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr,sc = W_tr.shape\n",
    "V = sigma_g2 / sc * W_tr @ W_tr.T + sigma_e2 * np.identity(n_tr)\n",
    "\n",
    "H_cv_lmm = np.zeros([n_tr,n_tr])\n",
    "H_cv_wls = np.zeros([n_tr,n_tr])\n",
    "H_cv_ols = np.zeros([n_tr,n_tr])\n",
    "\n",
    "H_cv_temp = np.zeros([n_tr,n_tr-1])\n",
    "# V_minusi_inv_storage = np.zeros([n_tr,n_tr-1,n_tr-1]) \n",
    "# Store the inverse of Variance to reduce time consumpution \n",
    "# Storge comsumption will be too large\n",
    "\n",
    "for i in range(n_tr):\n",
    "    indices_mi= list(range(n_tr))\n",
    "    indices_mi.remove(i)\n",
    "    V_minusi_inv = u.inv(V[indices_mi,:][:,indices_mi]) \n",
    "    X_minusi = X_tr[indices_mi, :]\n",
    "\n",
    "    inverse1 = u.inv(X_minusi.T @ V_minusi_inv @ X_minusi)\n",
    "    inverse2 = u.inv(X_minusi.T @  X_minusi)\n",
    "\n",
    "    beta_temp = inverse1 @ X_minusi.T @ V_minusi_inv\n",
    "    temp = X_tr[i,:] @ beta_temp\n",
    "    # H_cv_temp[i, ] = temp\n",
    "    H_cv_temp = X_minusi @ beta_temp\n",
    "\n",
    "    H_cv_wls[i, indices_mi] = temp\n",
    "    H_cv_lmm[i, indices_mi] = temp + \\\n",
    "        V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @\\\n",
    "             (np.identity(n_tr - 1) - H_cv_temp)\n",
    "\n",
    "    H_cv_ols[i, indices_mi] = X_tr[i,:] @ inverse2 @ X_minusi.T \n",
    "\n",
    "# for i in range(n_tr):\n",
    "#     indices_mi= list(range(n_tr))\n",
    "#     indices_mi.remove(i)\n",
    "#     H_cv_lmm[i, indices_mi] = H_cv_wls[i, indices_mi] + \\\n",
    "#         V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @ (np.identity(n_tr - 1) - H_cv_temp[indices_mi,: ])\n",
    "\n",
    "np.savez('Parameteres/H_cv LMM.npz', H_cv_ols = H_cv_ols,H_cv_wls = H_cv_wls, H_cv_lmm= H_cv_lmm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "LowRank is set as True, using REML\n",
      "Rank of W is 1673.\n",
      "delta: 0.5955727153476151\n",
      "Heritability h2: 0.6267342067090548\n",
      "Sigma_g2: 4407.204534663662\n",
      "Sigma_e2: 2624.81077180196\n"
     ]
    }
   ],
   "source": [
    "fast.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.6258332103107\n",
      "The CV error of   lmm is 2872.5647399580994, wls is 4021.7656889703244, and ols is 3958.7607906402673\n",
      "The CVc error of  lmm is 2928.19057316841, wls is 4024.6738744738504, and ols is 3985.3067672016114\n",
      "The test error of lmm is 3147.380021381683, wls is 4394.554386231235, and ols is 4301.224827649088\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using theoretical sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * sigma_g2 * W_tr @ W_te.T\n",
    "\n",
    "H_te_wls = X_te @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V(sigma_g2 = sigma_g2, sigma_e2 = sigma_e2)\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te - H_te_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "print('The CV error of   lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {}, wls is {}, and ols is {}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using estimated sigma value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------\n",
      "LowRank is set as True, using REML\n",
      "Rank of W is 1673.\n",
      "delta: 0.5955727153476151\n",
      "Heritability h2: 0.6267342067090548\n",
      "Sigma_g2: 4407.204534663662\n",
      "Sigma_e2: 2624.81077180196\n"
     ]
    }
   ],
   "source": [
    "fast.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr,sc = W_tr.shape\n",
    "V = fast.sigma_g2 / sc * W_tr @ W_tr.T + fast.sigma_e2 * np.identity(n_tr)\n",
    "\n",
    "H_cv_lmm2 = np.zeros([n_tr,n_tr])\n",
    "H_cv_wls2 = np.zeros([n_tr,n_tr])\n",
    "H_cv_ols2 = np.zeros([n_tr,n_tr])\n",
    "\n",
    "H_cv_temp = np.zeros([n_tr,n_tr-1])\n",
    "# V_minusi_inv_storage = np.zeros([n_tr,n_tr-1,n_tr-1]) \n",
    "# Store the inverse of Variance to reduce time consumpution \n",
    "# Storge comsumption will be too large\n",
    "\n",
    "for i in range(n_tr):\n",
    "    indices_mi= list(range(n_tr))\n",
    "    indices_mi.remove(i)\n",
    "    V_minusi_inv = u.inv(V[indices_mi,:][:,indices_mi]) \n",
    "    X_minusi = X_tr[indices_mi, :]\n",
    "\n",
    "    inverse1 = u.inv(X_minusi.T @ V_minusi_inv @ X_minusi)\n",
    "    inverse2 = u.inv(X_minusi.T @  X_minusi)\n",
    "\n",
    "    beta_temp = inverse1 @ X_minusi.T @ V_minusi_inv\n",
    "    temp = X_tr[i,:] @ beta_temp\n",
    "    H_cv_temp = X_minusi @ beta_temp\n",
    "\n",
    "    H_cv_wls2[i, indices_mi] = temp\n",
    "    H_cv_lmm2[i, indices_mi] = temp + \\\n",
    "        V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @\\\n",
    "             (np.identity(n_tr - 1) - H_cv_temp)\n",
    "\n",
    "    H_cv_ols2[i, indices_mi] = X_tr[i,:] @ inverse2 @ X_minusi.T \n",
    "#   H_cv_temp[i, ] = temp\n",
    "\n",
    "# for i in range(n_tr):\n",
    "#     indices_mi= list(range(n_tr))\n",
    "#     indices_mi.remove(i)\n",
    "#     H_cv_lmm[i, indices_mi] = H_cv_wls[i, indices_mi] + \\\n",
    "#         V[i, indices_mi] @ u.inv(V[indices_mi,:][:,indices_mi])  @ (np.identity(n_tr - 1) - H_cv_temp[indices_mi,: ])\n",
    "\n",
    "np.savez('Parameteres/H_cv LMM2.npz', H_cv_ols = H_cv_ols2,H_cv_wls = H_cv_wls2, H_cv_lmm= H_cv_lmm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error of   lmm is 2863.589204967364, wls is 4086.1420579337737, and ols is 3958.7607906402673\n",
      "The CVc error of  lmm is 2955.5977630071848, wls is 4089.113084571088, and ols is 4002.1606211191156\n",
      "The test error of lmm is 3125.187171464316, wls is 4482.009660400972, and ols is 4301.224827649088\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm2 @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls2 @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols2 @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using estimated sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * fast.sigma_g2 * W_tr @ W_te.T\n",
    "\n",
    "H_te_wls = X_te @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V()\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm2 @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls2 @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols2 @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te - H_te_ols @ y_tr)))\n",
    "\n",
    "print('The CV error of   lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {}, wls is {}, and ols is {}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with null space of w_tr testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import null_space\n",
    "null_V = null_space(W_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_te_in_null_V = null_V.T\n",
    "n_te_in_null_V = W_te_in_null_V.shape[0]\n",
    "X_te_in_null_V = np.concatenate([np.ones([n_te_in_null_V,1]), W_te_in_null_V[:, :num_large_effet_terms]], axis = 1)\n",
    "np.random.seed(0)\n",
    "epsilon = np.random.normal(0, np.sqrt(sigma_e2), n_te_in_null_V)\n",
    "y_te_in_null_V = W_te_in_null_V @ beta[1:]  + beta[0] + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error of   lmm is 3166.1290499916586, wls is 4086.1420579337723, and ols is 3958.7607906402673\n",
      "The CVc error of  lmm is 10967.655802624773, wls is 6582.661526050029, and ols is 10643.766022072985\n",
      "The test error of lmm is 777484.2286892927, wls is 777484.2286892927, and ols is 715767.2650530639\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm2 @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls2 @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols2 @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using estimated sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * fast.sigma_g2 * W_tr @ W_te_in_null_V.T\n",
    "\n",
    "H_te_wls = X_te_in_null_V @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te_in_null_V @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V()\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm2 @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls2 @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols2 @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te_in_null_V - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te_in_null_V - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te_in_null_V - H_te_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "print('The CV error of   lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {}, wls is {}, and ols is {}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with random generated test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "W_te_random = np.random.choice([0,1,2], [n_te, sc])\n",
    "X_te_random = np.concatenate([np.ones([n_te,1]), W_te_random[:, :num_large_effet_terms]], axis = 1)\n",
    "epsilon = np.random.normal(0, np.sqrt(sigma_e2), n_te)\n",
    "y_te_random = W_te_random@ beta[1:]  + beta[0] + epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error of   lmm is 3166.1290499916586, wls is 4086.1420579337723, and ols is 3958.7607906402673\n",
      "The CVc error of  lmm is 3088.5540679543146, wls is 4446.571102554026, and ols is 4848.4583546978365\n",
      "The test error of lmm is 7007735.62992001, wls is 6988273.477089207, and ols is 7136313.608272911\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm2 @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls2 @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols2 @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using estimated sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * fast.sigma_g2 * W_tr @ W_te_random.T\n",
    "\n",
    "H_te_wls = X_te_random @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te_random @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V()\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm2 @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls2 @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols2 @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te_random - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te_random - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te_random - H_te_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "print('The CV error of   lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {}, wls is {}, and ols is {}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(510,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3434438.8720892463"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_te_random_hat = X_te_random @ u.inv(X_te_random.T @ X_te_random) @ X_te_random.T @ y_te_random\n",
    "print(y_te_random_hat.shape)\n",
    "np.sum(np.square(y_te_random_hat - y_te_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV with k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2036, 1)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr[list(range(5))+ list(range(8, n_tr))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 fold indices : [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5)]\n"
     ]
    }
   ],
   "source": [
    "def H_function_ols(X_minus_k, X_k, y_minus_k, y_k ):\n",
    "    return X_k @ u.inv(X_minus_k.T @ X_minus_k) @ X_minus_k.T\n",
    "\n",
    "H_cv_ols_k = getHcv_for_Kfolds(X_tr, y_tr, H_function_ols, nfolds = n_tr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 fold indices : [(0, 204), (204, 408), (408, 612), (612, 816), (816, 1020)]\n"
     ]
    }
   ],
   "source": [
    "def H_function_wls(X_minus_k, X_k, y_minus_k, y_k, V):\n",
    "    V_inv = u.inv(V)\n",
    "    inverse = u.inv(X_minus_k.T @ V_inv @ X_minus_k) \n",
    "    return X_k @ inverse @ X_minus_k.T @ V_inv\n",
    "\n",
    "H_cv_wls_k = getHcv_for_Kfolds(X_tr, y_tr, H_function_wls, fast.V(), nfolds = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 fold indices : [(0, 204), (204, 408), (408, 612), (612, 816), (816, 1020)]\n"
     ]
    }
   ],
   "source": [
    "H_cv_lmm_k = np.zeros([n_tr, n_tr])\n",
    "V_inv = fast.V_inv()\n",
    "inverse = u.inv (X_tr.T @ V_inv @ X_tr)\n",
    "H_cv_temp = X_tr @ inverse @ X_tr.T @ V_inv\n",
    "\n",
    "folds_indices = get_folds_indices(10, n_tr)\n",
    "# get H_temp\n",
    "for Kindices in folds_indices:\n",
    "    ia,ib = Kindices\n",
    "    indices_minus_K = list(range(0, ia)) + list(range(ib, n_tr))\n",
    "\n",
    "    V_minus_k = V[indices_minus_K,:][:, indices_minus_K]\n",
    "    X_k = X_tr[ia:ib,:]\n",
    "    X_minus_k = X_tr[indices_minus_K,]\n",
    "\n",
    "    V_inv = u.inv(V_minus_k)\n",
    "\n",
    "    H_cv_temp = X_minus_k @ inverse @ X_minus_k.T @ V_inv\n",
    "\n",
    "    # inverse = u.inv(X_minus_k.T @ V_inv @ X_minus_k) \n",
    "\n",
    "    # temp =  X_k @ inverse @ X_minus_k.T @ V_inv\n",
    "    # H_cv_temp.append(temp)\n",
    "    \n",
    "    temp_u= V[ia:ib, indices_minus_K] @ u.inv(V_minus_k) @(\n",
    "        np.identity(n_tr - (ib - ia)) - H_cv_temp #[indices_minus_K,:][:, indices_minus_K]\n",
    "    )\n",
    "\n",
    "    H_cv_lmm_k[ia:ib, indices_minus_K] = H_cv_wls_k[ia:ib, indices_minus_K] + temp_u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error of   lmm is 2924.597316831033, wls is 4156.506837943065, and ols is 3958.7607906402673\n",
      "The CVc error of  lmm is 3084.366379786584, wls is 4252.30842376592, and ols is 4002.1606211191156\n",
      "The test error of lmm is 3125.187171464316, wls is 4482.009660400972, and ols is 4301.224827649088\n"
     ]
    }
   ],
   "source": [
    "# Using Test Error to estimate the Generalization error\n",
    "Error_cv_lmm = 1/n_tr * (np.sum(np.square(y_tr - H_cv_lmm_k @ y_tr)))\n",
    "Error_cv_wls = 1/n_tr * (np.sum(np.square(y_tr - H_cv_wls_k @ y_tr)))\n",
    "Error_cv_ols = 1/n_tr * (np.sum(np.square(y_tr - H_cv_ols_k @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "V_inv = fast.V_inv()\n",
    "# using estimated sigma_g2 to get the Covariance(y_tr, y_te)\n",
    "V_tr_te = 1/sc * fast.sigma_g2 * W_tr @ W_te.T\n",
    "\n",
    "H_te_wls = X_te @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv\n",
    "H_te_lmm = H_te_wls + V_tr_te.T @ V_inv @ (np.identity(n_tr) - X_tr @ u.inv(X_tr.T @ V_inv @ X_tr) @ X_tr.T @ V_inv) \n",
    "H_te_ols = X_te @ u.inv(X_tr.T @ X_tr) @ X_tr.T\n",
    "\n",
    "V = fast.V()\n",
    "Correction_lmm = 2 * (1/n_tr * np.trace(H_cv_lmm_k @ V) - 1/n_te * np.trace(H_te_lmm @ V_tr_te))\n",
    "Correction_wls = 2 * (1/n_tr * np.trace(H_cv_wls_k @ V) - 1/n_te * np.trace(H_te_wls @ V_tr_te))\n",
    "Correction_ols = 2 * (1/n_tr * np.trace(H_cv_ols_k @ V) - 1/n_te * np.trace(H_te_ols @ V_tr_te))\n",
    "\n",
    "Error_cv_lmm_c = Error_cv_lmm + Correction_lmm\n",
    "Error_cv_wls_c = Error_cv_wls + Correction_wls\n",
    "Error_cv_ols_c = Error_cv_ols + Correction_ols\n",
    "\n",
    "Error_te_lmm = 1/n_te *(np.sum(np.square(y_te - H_te_lmm @ y_tr)))\n",
    "Error_te_wls = 1/n_te *(np.sum(np.square(y_te - H_te_wls @ y_tr)))\n",
    "Error_te_ols = 1/n_te *(np.sum(np.square(y_te - H_te_ols @ y_tr)))\n",
    "\n",
    "\n",
    "\n",
    "print('The CV error of   lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm, Error_cv_wls, Error_cv_ols))\n",
    "print('The CVc error of  lmm is {}, wls is {}, and ols is {}'.format(Error_cv_lmm_c, Error_cv_wls_c, Error_cv_ols_c))\n",
    "print('The test error of lmm is {}, wls is {}, and ols is {}'.format(Error_te_lmm, Error_te_wls, Error_te_ols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge\n",
    "\n",
    "\n",
    "$$\n",
    "Q(\\boldsymbol{\\beta})=\\frac{1}{n}(\\mathbf{y}-\\mathbf{X} \\boldsymbol{\\beta})^{\\prime}(\\mathbf{y}-\\mathbf{X} \\boldsymbol{\\beta})+ \\lambda ||{\\beta}||_2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat \\beta = \\left(X^\\top X +n \\lambda \\mathbf{I} \\right)^{-1} X^{\\top} Y\n",
    "$$\n",
    "\n",
    "So the \n",
    "$$\n",
    "\\hat Y = H Y = X \\left(X^\\top X + n\\lambda \\mathbf{I} \\right)^{-1} X^{\\top} Y\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training and testing error of Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error of ridge is 3937.30, test error is 4296.72, corrected training error is 4029.31\n"
     ]
    }
   ],
   "source": [
    "n_tr,p = X_tr.shape\n",
    "\n",
    "nlamb = 10\n",
    "beta_without_y = u.inv(X_tr.T @ X_tr + nlamb * np.identity(p)) @ X_tr.T\n",
    "beta_hat_ridge = beta_without_y @ y_tr\n",
    "H_tr_ridge = X_tr @ beta_without_y\n",
    "H_te_ridge = X_te @ beta_without_y\n",
    "y_tr_hat_ridge = H_tr_ridge @ y_tr\n",
    "y_te_hat_ridge = H_te_ridge @ y_tr \n",
    "\n",
    "tr_error_ridge = 1/n_tr * np.sum((y_tr-y_tr_hat_ridge) ** 2)\n",
    "te_error_ridge = 1/n_te * np.sum((y_te-y_te_hat_ridge) ** 2)\n",
    "\n",
    "Correction_ridge = 2 * (1/n_tr * np.trace(H_tr_ridge @ V) - 1/n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "tr_error_ridge_c = tr_error_ridge + Correction_lmm\n",
    "print('training error of ridge is {:.2f}, test error is {:.2f}, corrected training error is {:.2f}'.\n",
    "    format(tr_error_ridge, te_error_ridge, tr_error_ridge_c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error of ridge is 1629.12, test error is 5291.02, sigma_e2 is 3321.627\n"
     ]
    }
   ],
   "source": [
    "print('training error of ridge is {:.2f}, test error is {:.2f}, sigma_e2 is {:.3f}'.format(tr_error_ridge, te_error_ridge, sigma_e2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOO Cross-valication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tr,p = X_tr.shape\n",
    "H_cv_ridge = np.zeros([n_tr,n_tr])\n",
    "\n",
    "lamb = 100 \n",
    "for i in range(n_tr):\n",
    "    indices_mi= list(range(n_tr))\n",
    "    indices_mi.remove(i)\n",
    "    X_minusi = X_tr[indices_mi, :]\n",
    "    inverse = u.inv(X_minusi.T @  X_minusi + lamb * np.diag(np.ones(p)) )\n",
    "\n",
    "    temp = X_tr[i,:] @ inverse @ X_minusi.T  \n",
    "    H_cv_ridge[i, indices_mi] = temp\n",
    "\n",
    "np.savez('Parameters/H_cv ridge.npz', H_cv_ridge = H_cv_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error and CVc error and test error of ridge are 3971.16, 4005.64, 4310.60\n"
     ]
    }
   ],
   "source": [
    "Error_cv_ridge = 1/n_tr * (np.sum((y_tr - H_cv_ridge @ y_tr)**2))\n",
    "\n",
    "H_te_ridge = X_te @ u.inv(X_tr.T @ X_tr + lamb * np.identity(p)) @ X_tr.T\n",
    "Error_te_ridge = 1/n_te * (np.sum((y_te - H_te_ridge @ y_tr)**2))\n",
    "\n",
    "\n",
    "Correction_ridge = 2  * (np.trace(H_cv_ridge @ V)/n_tr - np.trace(H_te_ridge @ V_tr_te) /n_te)\n",
    "Error_cv_ridge_c = Error_cv_ridge + Correction_ridge\n",
    "\n",
    "print('The CV error and CVc error and test error of ridge are {:.2f}, {:.2f}, {:.2f}'\n",
    ".format(Error_cv_ridge, Error_cv_ridge_c, Error_te_ridge))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CV with k folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 fold indices : [(0, 1020), (1020, 2039)]\n"
     ]
    }
   ],
   "source": [
    " \n",
    "def H_function_ridge(X_minus_k, X_k, y_minus_k, y_k ):\n",
    "\n",
    "    return X_k @ u.inv(X_minus_k.T @ X_minus_k + lamb * np.identity(X_minus_k.shape[1])) @ X_minus_k.T\n",
    "\n",
    "H_cv_ridge_k = getHcv_for_Kfolds(X_tr, y_tr, H_function_ridge, nfolds = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CV error and CVc error and test error of ridge are 4005.21, 3981.10, 4310.60\n"
     ]
    }
   ],
   "source": [
    "V = fast.V()\n",
    "V_tr_te = 1/sc * fast.sigma_g2* W_tr @ W_te.T\n",
    "Error_cv_ridge = 1/n_tr * (np.sum((y_tr - H_cv_ridge_k @ y_tr)**2))\n",
    "\n",
    "H_te_ridge = X_te @ u.inv(X_tr.T @ X_tr + lamb * np.identity(p)) @ X_tr.T\n",
    "Error_te_ridge = 1/n_te * (np.sum((y_te - H_te_ridge @ y_tr)**2))\n",
    "\n",
    "\n",
    "Correction_ridge = 2  * (1/n_tr*np.trace(H_cv_ridge_k @ V) - 1/n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "Error_cv_ridge_c = Error_cv_ridge + Correction_ridge\n",
    "\n",
    "print('The CV error and CVc error and test error of ridge are {:.2f}, {:.2f}, {:.2f}'\n",
    ".format(Error_cv_ridge, Error_cv_ridge_c, Error_te_ridge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-14.747054866241797\n",
      "The CV error and CVc error and test error of ridge are 4005.21, 3990.46, 4310.60\n"
     ]
    }
   ],
   "source": [
    "sigma_g2_test = sigma_g2 \n",
    "# using theoretical sigma\n",
    "# V = fast.V(sigma_g2=sigma_g2_test, sigma_e2 = sigma_e2)\n",
    "V =  1/sc * sigma_g2_test * W_tr @ W_tr.T + sigma_e2 * np.identity(X_tr.shape[0])\n",
    "V_tr_te = 1/sc * sigma_g2_test * W_tr @ W_te.T\n",
    "Error_cv_ridge = 1/n_tr * (np.sum((y_tr - H_cv_ridge_k @ y_tr)**2))\n",
    "\n",
    "H_te_ridge = X_te @ u.inv(X_tr.T @ X_tr + lamb * np.identity(p)) @ X_tr.T\n",
    "Error_te_ridge = 1/n_te * (np.sum((y_te - H_te_ridge @ y_tr)**2))\n",
    "\n",
    "\n",
    "Correction_ridge = 2  * (1/n_tr*np.trace(H_cv_ridge_k @ V) - 1/n_te * np.trace(H_te_ridge @ V_tr_te))\n",
    "Error_cv_ridge_c = Error_cv_ridge + Correction_ridge\n",
    "\n",
    "print(Correction_ridge)\n",
    "print('The CV error and CVc error and test error of ridge are {:.2f}, {:.2f}, {:.2f}'\n",
    ".format(Error_cv_ridge, Error_cv_ridge_c, Error_te_ridge))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b09ec625f77bf4fd762565a912b97636504ad6ec901eb2d0f4cf5a7de23e1ee5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
